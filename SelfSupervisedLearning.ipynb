{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SelfSupervisedLearning.ipynb","provenance":[],"authorship_tag":"ABX9TyOaxMU5x9s0DQweGOJIVH3a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"vWXMj67bIKXj","executionInfo":{"status":"ok","timestamp":1648534057670,"user_tz":-330,"elapsed":970,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}}},"outputs":[],"source":["import re\n","import numpy as np\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_eager_execution()\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","\n","import matplotlib\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["EETA_DEFAULT = 0.001\n","\n","class LARSOptimizer(tf.train.Optimizer):\n","  \"\"\"Layer-wise Adaptive Rate Scaling for large batch training.\n","\n","  Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n","  I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n","  \"\"\"\n","\n","  def __init__(self,\n","               learning_rate,\n","               momentum=0.9,\n","               use_nesterov=False,\n","               weight_decay=0.0,\n","               exclude_from_weight_decay=None,\n","               exclude_from_layer_adaptation=None,\n","               classic_momentum=True,\n","               eeta=EETA_DEFAULT,\n","               name=\"LARSOptimizer\"):\n","    \"\"\"Constructs a LARSOptimizer.\n","\n","    Args:\n","      learning_rate: A `float` for learning rate.\n","      momentum: A `float` for momentum.\n","      use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n","      weight_decay: A `float` for weight decay.\n","      exclude_from_weight_decay: A list of `string` for variable screening, if\n","          any of the string appears in a variable's name, the variable will be\n","          excluded for computing weight decay. For example, one could specify\n","          the list like ['batch_normalization', 'bias'] to exclude BN and bias\n","          from weight decay.\n","      exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n","          for layer adaptation. If it is None, it will be defaulted the same as\n","          exclude_from_weight_decay.\n","      classic_momentum: A `boolean` for whether to use classic (or popular)\n","          momentum. The learning rate is applied during momeuntum update in\n","          classic momentum, but after momentum for popular momentum.\n","      eeta: A `float` for scaling of learning rate when computing trust ratio.\n","      name: The name for the scope.\n","    \"\"\"\n","    super(LARSOptimizer, self).__init__(False, name)\n","\n","    self.learning_rate = learning_rate\n","    self.momentum = momentum\n","    self.weight_decay = weight_decay\n","    self.use_nesterov = use_nesterov\n","    self.classic_momentum = classic_momentum\n","    self.eeta = eeta\n","    self.exclude_from_weight_decay = exclude_from_weight_decay\n","    # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n","    # arg is None.\n","    if exclude_from_layer_adaptation:\n","      self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n","    else:\n","      self.exclude_from_layer_adaptation = exclude_from_weight_decay\n","\n","  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n","    if global_step is None:\n","      global_step = tf.train.get_or_create_global_step()\n","    new_global_step = global_step + 1\n","\n","    assignments = []\n","    for (grad, param) in grads_and_vars:\n","      if grad is None or param is None:\n","        continue\n","\n","      param_name = param.op.name\n","\n","      v = tf.get_variable(\n","          name=param_name + \"/Momentum\",\n","          shape=param.shape.as_list(),\n","          dtype=tf.float32,\n","          trainable=False,\n","          initializer=tf.zeros_initializer())\n","\n","      if self._use_weight_decay(param_name):\n","        grad += self.weight_decay * param\n","\n","      if self.classic_momentum:\n","        trust_ratio = 1.0\n","        if self._do_layer_adaptation(param_name):\n","          w_norm = tf.norm(param, ord=2)\n","          g_norm = tf.norm(grad, ord=2)\n","          trust_ratio = tf.where(\n","              tf.greater(w_norm, 0), tf.where(\n","                  tf.greater(g_norm, 0), (self.eeta * w_norm / g_norm),\n","                  1.0),\n","              1.0)\n","        scaled_lr = self.learning_rate * trust_ratio\n","\n","        next_v = tf.multiply(self.momentum, v) + scaled_lr * grad\n","        if self.use_nesterov:\n","          update = tf.multiply(self.momentum, next_v) + scaled_lr * grad\n","        else:\n","          update = next_v\n","        next_param = param - update\n","      else:\n","        next_v = tf.multiply(self.momentum, v) + grad\n","        if self.use_nesterov:\n","          update = tf.multiply(self.momentum, next_v) + grad\n","        else:\n","          update = next_v\n","\n","        trust_ratio = 1.0\n","        if self._do_layer_adaptation(param_name):\n","          w_norm = tf.norm(param, ord=2)\n","          v_norm = tf.norm(update, ord=2)\n","          trust_ratio = tf.where(\n","              tf.greater(w_norm, 0), tf.where(\n","                  tf.greater(v_norm, 0), (self.eeta * w_norm / v_norm),\n","                  1.0),\n","              1.0)\n","        scaled_lr = trust_ratio * self.learning_rate\n","        next_param = param - scaled_lr * update\n","\n","      assignments.extend(\n","          [param.assign(next_param),\n","           v.assign(next_v),\n","           global_step.assign(new_global_step)])\n","    return tf.group(*assignments, name=name)\n","\n","  def _use_weight_decay(self, param_name):\n","    \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n","    if not self.weight_decay:\n","      return False\n","    if self.exclude_from_weight_decay:\n","      for r in self.exclude_from_weight_decay:\n","        if re.search(r, param_name) is not None:\n","          return False\n","    return True\n","\n","  def _do_layer_adaptation(self, param_name):\n","    \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n","    if self.exclude_from_layer_adaptation:\n","      for r in self.exclude_from_layer_adaptation:\n","        if re.search(r, param_name) is not None:\n","          return False\n","    return True"],"metadata":{"id":"GT-APezpIyar","executionInfo":{"status":"ok","timestamp":1648534061942,"user_tz":-330,"elapsed":791,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGTV4o_5JlqN","executionInfo":{"status":"ok","timestamp":1648534071285,"user_tz":-330,"elapsed":4149,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}},"outputId":"138cbd7c-822a-4884-830f-d708e7d9ac13"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls -la \"/content/gdrive/My Drive/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbsb8HaUJ5vk","executionInfo":{"status":"ok","timestamp":1648534074416,"user_tz":-330,"elapsed":675,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}},"outputId":"a72fd03e-cc32-4067-8478-3b0bdab5152a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["total 431350\n","-rw------- 1 root root  40115107 May 24  2021  3.mp4\n","drwx------ 2 root root      4096 Sep 23  2021  clip_test_video\n","-rw------- 1 root root 390881531 Jul 14  2021  Code.zip\n","drwx------ 2 root root      4096 Apr 15  2021 'Colab Notebooks'\n","drwx------ 2 root root      4096 Mar 13  2020  darknet\n","drwx------ 2 root root      4096 Oct 15  2020 'Deep Learning'\n","drwx------ 2 root root      4096 Apr 21  2021  demo\n","drwx------ 2 root root      4096 Dec 14 11:52  fk\n","drwx------ 2 root root      4096 Sep 23  2021  frames\n","-rw------- 1 root root   1560010 Mar 13  2020 'Getting started.pdf'\n","drwx------ 2 root root      4096 Mar 29 05:24  kissing_images\n","-rw------- 1 root root   9107527 May 25  2021  sub.mp4\n","drwx------ 2 root root      4096 Mar 10  2021  TestData\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.applications.efficientnet_v2 import EfficientNetV2B2, preprocess_input\n","from keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from pathlib import Path"],"metadata":{"id":"HtyHSAgjKDIT","executionInfo":{"status":"ok","timestamp":1648534134196,"user_tz":-330,"elapsed":725,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class_subset = [\"kiss\", \"neutral\"]"],"metadata":{"id":"EvMurAOUKDNz","executionInfo":{"status":"ok","timestamp":1648534219928,"user_tz":-330,"elapsed":720,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["#data loading\n","BATCH_SIZE = 64\n","\n","train_generator = ImageDataGenerator(rotation_range=90,\n","                                     brightness_range=[0.1, 0.7],\n","                                     width_shift_range=0.5,\n","                                     height_shift_range=0.5,\n","                                     horizontal_flip=True,\n","                                     vertical_flip=True,\n","                                     validation_split=0.15,\n","                                     preprocessing_function=preprocess_input) # VGG16 preprocessing\n","\n","test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # VGG16 preprocessing\n","\n","download_dir = Path('/content/gdrive/My Drive/kissing_images')\n","train_data_dir = download_dir/'train'\n","test_data_dir = download_dir/'test'\n","\n","class_subset = [\"kiss\", \"neutral\"]\n","\n","traingen = train_generator.flow_from_directory(train_data_dir,\n","                                               target_size=(224, 224),\n","                                               class_mode='categorical',\n","                                               classes=class_subset,\n","                                               subset='training',\n","                                               batch_size=BATCH_SIZE,\n","                                               shuffle=True,\n","                                               seed=42)\n","\n","validgen = train_generator.flow_from_directory(train_data_dir,\n","                                               target_size=(224, 224),\n","                                               class_mode='categorical',\n","                                               classes=class_subset,\n","                                               subset='validation',\n","                                               batch_size=BATCH_SIZE,\n","                                               shuffle=True,\n","                                               seed=42)\n","\n","testgen = test_generator.flow_from_directory(test_data_dir,\n","                                             target_size=(224, 224),\n","                                             class_mode=None,\n","                                             classes=class_subset,\n","                                             batch_size=1,\n","                                             shuffle=False,\n","                                             seed=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gwSMbTq5JQ8m","executionInfo":{"status":"ok","timestamp":1648534147562,"user_tz":-330,"elapsed":10589,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}},"outputId":"5bad15f8-c65c-4ad0-bfcc-88a9b7de571b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3099 images belonging to 2 classes.\n","Found 546 images belonging to 2 classes.\n","Found 868 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["#@title Load module and construct the computation graph\n","\n","learning_rate = 0.1\n","momentum = 0.9\n","weight_decay = 0.\n","\n","# Load the base network and set it to non-trainable (for speedup fine-tuning)\n","hub_path = 'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/'\n","module = hub.Module(hub_path, trainable=False)\n","key = module(inputs=train_generator, signature=\"default\", as_dict=True)\n","\n","# Attach a trainable linear layer to adapt for the new task.\n","with tf.variable_scope('head_supervised_new', reuse=tf.AUTO_REUSE):\n","  logits_t = tf.layers.dense(inputs=key['final_avg_pool'], units=2)\n","loss_t = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n","    labels=tf.one_hot(class_subset, 2), logits=logits_t))\n","\n","# Setup optimizer and training op.\n","optimizer = LARSOptimizer(\n","    learning_rate,\n","    momentum=momentum,\n","    weight_decay=weight_decay,\n","    exclude_from_weight_decay=['batch_normalization', 'bias', 'head_supervised'])\n","variables_to_train = tf.trainable_variables() \n","train_op = optimizer.minimize(\n","    loss_t, global_step=tf.train.get_or_create_global_step(),\n","    var_list=variables_to_train)\n","\n","print('Variables to train:', variables_to_train)\n","key # The accessible tensor in the return dictionary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"id":"GPOMw_5SJXnI","executionInfo":{"status":"error","timestamp":1648534262433,"user_tz":-330,"elapsed":5813,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}},"outputId":"ce54a372-7b35-43aa-cbb9-413cec7d1d7c"},"execution_count":19,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    264\u001b[0m                issubclass(v.dtype.type, expected_types))):\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0m_check_failed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_check_failed\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    245\u001b[0m   \u001b[0;31m# it is safe to use here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: <keras.preprocessing.image.ImageDataGenerator object at 0x7f6acc708990>","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    165\u001b[0m       tensor = tf.compat.v1.convert_to_tensor_or_indexed_slices(\n\u001b[0;32m--> 166\u001b[0;31m           value, target.dtype)\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m   return internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m--> 289\u001b[0;31m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    326\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    285\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    287\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m       raise TypeError(f\"Expected {dtype.name}, but got {mismatch} of type \"\n\u001b[0m\u001b[1;32m    333\u001b[0m                       f\"'{type(mismatch).__name__}'.\")\n","\u001b[0;31mTypeError\u001b[0m: Expected float32, but got <keras.preprocessing.image.ImageDataGenerator object at 0x7f6acc708990> of type 'ImageDataGenerator'.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-2e5265e6c698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhub_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://simclr-checkpoints/simclrv2/finetuned_100pct/r50_1x_sk0/hub/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Attach a trainable linear layer to adapt for the new task.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0m_check_supported_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n\u001b[1;32m    267\u001b[0m         \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    480\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 482\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 205\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    166\u001b[0m           value, target.dtype)\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m   \u001b[0mtensor_type_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_type_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mtarget_type_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_type_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Can't convert 'images': Expected float32, but got <keras.preprocessing.image.ImageDataGenerator object at 0x7f6acc708990> of type 'ImageDataGenerator'."]}]},{"cell_type":"code","source":["sess = tf.Session()\n","sess.run(tf.global_variables_initializer())"],"metadata":{"id":"7ncSqKsnJaTU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title We fine-tune the new *linear layer* for just a few iterations.\n","\n","total_iterations = 10\n","\n","for it in range(total_iterations):\n","  _, loss, image, logits, labels = sess.run((train_op, loss_t, x['image'], logits_t, x['label']))\n","  pred = logits.argmax(-1)\n","  correct = np.sum(pred == labels)\n","  total = labels.size\n","  print(\"[Iter {}] Loss: {} Top 1: {}\".format(it+1, loss, correct/float(total)))"],"metadata":{"id":"Egpdaq_xJaWz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Plot the images and predictions\n","fig, axes = plt.subplots(5, 1, figsize=(15, 15))\n","for i in range(5):\n","  axes[i].imshow(image[i])\n","  true_text = tf_flowers_labels[labels[i]]\n","  pred_text = tf_flowers_labels[pred[i]]\n","  axes[i].axis('off')\n","  axes[i].text(256, 128, 'Truth: ' + true_text + '\\n' + 'Pred: ' + pred_text)"],"metadata":{"id":"aR5FuGl4JaaK"},"execution_count":null,"outputs":[]}]}