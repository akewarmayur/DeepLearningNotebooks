{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21739,"status":"ok","timestamp":1685359433167,"user":{"displayName":"mike yolo","userId":"10130328056325800129"},"user_tz":-330},"id":"Yts0qTtsvd0E","outputId":"d077fb31-10aa-4c9e-86f8-9c324aefefb4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":[],"metadata":{"id":"U-YKGdBoh6zy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27236,"status":"ok","timestamp":1685359463736,"user":{"displayName":"mike yolo","userId":"10130328056325800129"},"user_tz":-330},"id":"eDwreJNzvu-g","outputId":"1fb74030-149d-4137-a655-c33a7d799b74"},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.110 ðŸš€ Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.4/78.2 GB disk)\n"]}],"source":["# !pip install git+https://github.com/m-bain/whisperx.git@v3\n","!pip install ultralytics\n","!pip install -q gradio\n","from IPython import display\n","display.clear_output()\n","\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gahTHp-bLnwU"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from ultralytics import YOLO\n","# import whisperx\n","import os\n","from moviepy.editor import *\n","from google.colab.patches import cv2_imshow\n","import moviepy.editor as mp\n","import gradio as gr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaNTSNcIbNfr","colab":{"base_uri":"https://localhost:8080/","height":767},"executionInfo":{"status":"ok","timestamp":1685360131991,"user_tz":-330,"elapsed":6056,"user":{"displayName":"mike yolo","userId":"10130328056325800129"}},"outputId":"4488cb96-1192-4150-e57e-e85e29a20294"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:295: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  warnings.warn(\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:298: UserWarning: `optional` parameter is deprecated, and it has no effect\n","  super().__init__(format=type, source=source, label=label, optional=optional)\n","\n","WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gradio/outputs.py:98: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n","  warnings.warn(\n","\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://81e964173c003c49d1.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://81e964173c003c49d1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":6}],"source":["\n","# Step 1: Input is a video\n","def process_video(input_video):\n","\n","  # Step 2: Extract frames\n","  video = cv2.VideoCapture(input_video)\n","  fps = video.get(cv2.CAP_PROP_FPS)\n","  frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n","  frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","  output_video = \"/content/gdrive/My Drive/demoM/test_images/output_video.mp4\"\n","  output_writer = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (frame_width, frame_height))\n","\n","  # Step 3: Pass each frame to a model to detect objects\n","  model = YOLO(\"/content/gdrive/My Drive/demoM/trainedModel/bestV1.pt\")\n","\n","  # Step 4: Extract audio from the input video\n","  video_clip = mp.VideoFileClip(input_video)\n","  audio_clip = video_clip.audio\n","  audio_clip.write_audiofile(\"temp_audio.wav\")\n","\n","  while True:\n","      # Read the next frame\n","      try:\n","        ret, frame = video.read()\n","        if not ret:\n","            break\n","        # Step 5: Get the mask of the object and blur the mask\n","        results = model.predict(source=frame, conf=0.5)\n","        objects_mask = results[0].masks.xy\n","        mask_ = np.zeros_like(frame)\n","        for mask in objects_mask:\n","          vertices = mask.reshape(mask.shape[0], mask.shape[1] // 2, 2)\n","          cv2.fillPoly(mask_, np.int32([vertices]), (255, 255, 255))\n","          #blurred_region1 = cv2.blur(frame, (20, 20), 10)\n","          blurred_region2 = cv2.GaussianBlur(frame, (53, 53), 30)\n","          output_frame = np.where(mask_ != 0, blurred_region2, frame)\n","        output_writer.write(output_frame)\n","      except Exception as e:\n","        output_writer.write(frame)\n","\n","  # Release the video capture and writer, and close windows\n","  video.release()\n","  output_writer.release()\n","\n","  # Step 8: Merge the output video with the audio using moviepy\n","  final_output = mp.VideoFileClip(output_video)\n","  final_output = final_output.set_audio(mp.AudioFileClip(\"temp_audio.wav\"))\n","  final_output.write_videofile(\"/content/gdrive/My Drive/demoM/test_images/final_output_video.mp4\", codec=\"libx264\", audio_codec=\"aac\", remove_temp=True)\n","  return \"/content/gdrive/My Drive/demoM/test_images/final_output_video.mp4\"\n","\n","\n","# Define the input and output components\n","input_video = gr.inputs.Video(type=\"mp4\", label=\"Input Video\")\n","output_video = gr.outputs.File(label=\"Processed Video\")\n","\n","# Create the Gradio interface\n","interface = gr.Interface(fn=process_video, inputs=input_video, outputs=output_video)\n","\n","# Launch the interface\n","interface.launch(share=True)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1u5ATG7O7Zn5kcr7pY_B6FWzpfTyACaSe","timestamp":1685359088806}],"gpuType":"T4","authorship_tag":"ABX9TyMVZ5F/5WkNdnvgZsa/tYJv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}